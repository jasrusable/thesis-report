\documentclass[11pt,a4paper]{report}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage[backend=bibtex]{biblatex}
\graphicspath{{./images/}}
\addbibresource{sources.bib}

\title{Indoor positioning using the comparison of digital imagery to 3D models}
\date{2015}
\author{Jason David Russell}

\begin{document}

\maketitle
\thispagestyle{empty}

\pagenumbering{roman}
\setcounter{page}{0}

\newpage
\chapter*{Plagiarism Declaration}
	\addcontentsline{toc}{chapter}{Plagiarism Declaration}
	\begin{enumerate}
		\item
			I know that plagiarism means taking and using the ideas, writings, works or inventions of another as if they were one's own. I know that plagiarism not only includes verbatim copying, but also the extensive use of another person's ideas without proper acknowledgement (which includes the proper use of quotation marks). I know that plagiarism covers this sort of use of material found in textual sources and from the Internet.
		\item
			I acknowledge and understand that plagiarism is wrong.
		\item
			I understand that my research must be accurately referenced. I have followed the rules and conventions concerning referencing, citation and the use of quotations as set out in the Departmental Guide.
		\item
			This assignment is my own work, or my group's own unique group assignment.
			I acknowledge that copying someone else's assignment, or part of it, is wrong, and that submitting identical work to others constitutes a form of plagiarism.
		\item
			I have not allowed, nor will I in the future allow, anyone to copy my work with the intention of passing it off as their own work.
	\end{enumerate}
	Jason David Russell

\newpage
\chapter*{Acknowledgements}
	\addcontentsline{toc}{chapter}{Acknowledgements}
	I acknowledge everything.

\newpage
\chapter*{Abstract}
	\addcontentsline{toc}{chapter}{Abstract}
	This paper investigates the viability of a new indoor positioning system which is to make use of the comparison of digital imagery to 3D models. An example scenario would be a person wishing to know which room they are in within a building. A 3D model of the building exists. The person takes a few photographs of her surroundings, the photographs are then compared to the 3D model and the result is presented to the person. The main focus of this paper is on the matching of the images to the 3D model.

\newpage
\tableofcontents

\newpage
\listoffigures

\pagenumbering{arabic}
\setcounter{page}{0}

\newpage
\chapter{Introduction}
	\section{Subject of the Report}
		This report concerns the viability of an alternate indoor positioning method. The method involves comparing a photograph to a 3D interior model in order to determine the location of the photographer.
	
	\section{Background to the Report}
		3D interior models are becoming more and more prominent. New technological advancements and techniques are making it cheaper, quicker and easier to generate interior 3D models. Combine the recent prominence of 3D interior models with the ubiquity of camera equipped smart phones and a new indoor positioning system presents itself. This system depends on the matching of a photograph to a 3D interior model in order to locate the photographer. Thus, the primary focus of this paper is on the matching of a photograph to a 3D interior model.
	
	\section{Objectives of the Report}
		The objectives of this report are therefore to:
		\begin{itemize}
			\item
				discuss related work
			\item
				discuss the alternate method and its requirements
			\item
				present experimental results
			\item
				 consider future work
			\item
				draw conclusions
		\end{itemize}
	
	\section{Scope and limitations}
		Some scope and limitation stuff goes here.
	
	\section{Plan of Development}
		This report begins by looking at work related to indoor positioning systems. Following on from that, the alternate method will be proposed. Thereafter results of investigations will be presented and discussed.

\newpage
\chapter{Related Work}
	In the sections to follow, existing indoor positioning systems will be discussed. Two main branches of technologies will be covered, namely radio and non-radio technologies.
	
	\section{Radio technologies}
		Any wireless technology can in theory, be used for positioning. Three main techniques exist, each one will be briefly outlined below. The sections to follow will look at existing systems which employ these techniques.
	
	\subsection{Time of arrival}
		\begin{figure}[h!]
			\centering
			\includegraphics[width=0.6\textwidth]{time_of_arrival}
			\caption{Time of arrival}
		\end{figure}
		Time of arrival (or time of flight) is the travel time of a radio signal from a single transmitter to a single remote receiver. The basic observable is time. A Distance can be directly calculated using the known propagation velocity of signals with the basic observable time. Location can then be determined using multi-lateration. This requires a setup of at least one receiver and three transmitters or vise versa.
		Required with such systems is the synchronization of clocks between receivers and transmitters.
		Time of travel systems suffer greatly from effects such as multi-path.
		\cite{k._pahlavan_wideband_1998}
	
	\subsection{Received signal strength indication}
		\begin{figure}[h!]
			\centering
			\includegraphics[width=0.6\textwidth]{rssi}
			\caption{RSSI}
		\end{figure}
		Received signal strength indication is a measure of the power level received by a sensor. Because of how radio waves propagate, distance can be approximated between a transmitter and receiver based on the relationship between the transmitted and received signal strength. Multi-lateration can be used to determine locality of a sensor.
	
	\subsection{Angle of arrival}
		\begin{figure}[h!]
			\centering
			\includegraphics[width=0.6\textwidth]{angle_of_arrival}
			\caption{Angle of arrival}
		\end{figure}
		Angle of arrival is the angle from which a signal is received at a receiver. Angle of arrival is typically determined by using the time difference of arrival between multiple antennas in a sensor array. Position is determined using multi-angulation.
		Angle of arrival systems also suffer from effects such as multi-path.
	
	\subsection{Wi-Fi based systems}
		Wi-Fi based technologies are based on measurements such as TOA (time of arrival), TDOA (time difference of arrival) and DOA (direction of arrival). However these techniques are severely impaired when line of sight is not achievable. These techniques also suffer due to objects such as walls and floors and other objects which attenuate and reflect the signals, directly affecting accuracies.
	
		An alternative Wi-Fi based geolocation method has been explored which makes use of relative signal strengths between transmitters and receivers. So instead of measuring the time or angle of signals, the signal strength is used to determine location. This negates many of the above mentioned deficiencies. A similar system has been employed by animal trackers with directional antennas.
		\cite{yongguang_chen_signal_2002}
	
	\subsection{Blue-tooth systems}
		Blue-tooth positioning works by using proximities, as opposed to angulation or lateration. As such, exact locations are not attainable using these techniques. Instead, the system acts more as a geofence and works by determining which node a device is currently connected to in order to determine the location of the device.
	
		Apple has developed a protocol called iBeacon. This protocol makes use fo Blue-tooth proximity techniques in order to enable smart devices to perform actions when in close proximity to iBeacon.
		\cite{_everything_????}
	
	\subsection{Choke point concepts}
		Choke point systems work by locating and indexing tagged objects in order to track them. The concept works by passing tagged objects though a choke point (or gate), the choke point will then have a sensor which detects the tagged object passing through the gate. Many choke point sensors work with passive radio-frequency identification (RFID) tags which do not report distances or signal strengths.
		\cite{reza_investigation_2008}
	
	\subsection{Grid concepts}
		Grid concepts employ a dense network of low-range receivers arranged in a known pattern. A tagged object will be sensed by only a few nearby, networks receivers. By determining which receivers and tag is sensed by, a rough approximation of the location of the tagged object can be made.
	
	\subsection{Others}
		Various other systems exist but will not be discussed further. These include ultra-wide band (UWB), infrared (IR), visible light communication, and ultrasound.
	
	\section{Non-radio technologies}
		Non-radio technologies which can be used for indoor positioning will be discussed below. These systems can provide increased accuracy at the expense of increased costs of equipment and additional installations.
	
	\subsection{Magnetic positioning}
		Magnetic positioning takes advantage of the way iron in buildings affects the Earth's magnetic field. The iron in buildings creates local variations in the Earth's magnetic field which can then be sensed by compasses to map indoor locations.
		\cite{supreeth_sudhakaran_geospatial_2014}
	
	\subsection{Inertial measurements}
		Inertial measurement units (IMUs) can be carried by an object in order to track the objects path through space. IMUs measure acceleration and orientation along three orthogonal axis using accelerometers and gyroscopes. Position can be determined by double integration of the acceleration measurements - this is a form of dead reckoning. Dead reckoning is the process of calculating ones current location by using previously determined positions with estimated speed and orientation over some time. This yields relative position estimations. Dead reckoning is subject to what is known as drift which is an accumulation of errors. Due to the susceptibility of IMUs to drift, they are often used in conjunction with other positioning systems in order to correct for this drift.

\newpage
\chapter{Method}
	There are two main requirements for this alternate indoor positioning method. The first requirement is to have a 3D model of an environment. The second requirement is a photograph of a scene within that environment. The premise is that the photograph could be queried against the 3D model in order to determine where the photograph was taken within that 3D model, thus locating the photographer.
	
	The querying of the photograph against the model presents a problem, and that is that the photograph and the 3D model are not intrinsically comparable. So how does one compare an image to a 3D model? A solution to this problem is to create renderings throughout the model and compare these renderings to the photograph. These renderings are themselves images and so this permits the use of advanced and robust image recognition software to perform the matching.
	
	In the following sections, the processes of creating the 3D interior model, taking a photograph and comparing the photograph to the renders of the 3D model will be discussed in detail.
	
	The front door section of the Geomatics Teaching Laboratory was used as the basis of this investigation. The Geomatics Teaching Laboratory is located on the fifth floor of the Menzies building at UCT.
		
	\section{The 3D model}
		3D modelling can be described as the process of developing a mathematical representation of a three dimensional space using specialized software. The product of this process is called a 3D model. A 3D model can be visualized as a two dimensional image through a process called 3D rendering. It is this two dimensional image representation of a 3D model which is utilized to perform the comparison to a photograph in this alternate indoor positioning system.
		
		\subsection{3D Interior Model creation}
			3D models can be created automatically or manually. Examples of automatic techniques include structure from motion. Manual creation of 3D models involves construction by hand using advanced computer software such as Blender. In order to accurately model an existing environment, raw data such as measurements or point clouds is needed to serve as a basis for the model creation, it serves as the initial building block for the model. This raw data can be in a variety of forms, this will be discussed in the section to follow.
		
			\subsubsection{Data acquisition}
				In order to create an accurate 3D model of a building, data is required in order to aid the modelling process and serve as a template. This data can come in the form of building plans, measured distances and directions or point clouds etc.
				For this investigation, a point cloud was used. A laser scan of the Geomatics Teaching Laboratory (GTL) was carried out using a {{laser Scanner model}} at {{laser scanner settings, resolution etc}}. 
				
				The end result was a high resolution point cloud of the rooms interior. {{Insert Point Cloud image}}.
				
			\subsubsection{Data preprocessing}
				Cleaning the point cloud.
				Removing superfluous points.
				
			\subsubsection{Constructing the model}
				Maybe explain B-rep and CSG?
				Model constructed using Blender.
				PC serves as template for modelling.
					Fitting surfaces to points.
				
			

			Automated techniques failed
			Model created with Blender + point cloud
			Discuss level of detail
				Elements (degree of detail)
					Include conduate, wall plugs, white-board seams etc
				Lighting/shadows
					Position of lights and shadows, type of lights
				Texture
					Rough texture for carpet, smooth texture for glass panel on door
				Image draping
					Image draped over air vent
		\subsection{Python Framework}
			How feature detection works
			How feature matching works
			Homogrophy
			SIFT/SURF/ORB
					

\chapter{Experimental implementation results}

\chapter{Discussions}

\chapter{Conclusions and future work}

\newpage
\printbibliography

\end{document}