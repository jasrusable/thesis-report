\documentclass[11pt,a4paper]{report}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage[backend=bibtex]{biblatex}
\graphicspath{{./images/}}
\addbibresource{sources.bib}

\title{Indoor positioning using the comparison of digital imagery to 3D models}
\date{2015}
\author{Jason David Russell}

\begin{document}

\maketitle
\thispagestyle{empty}

\pagenumbering{roman}
\setcounter{page}{0}

\newpage
\chapter*{Plagiarism Declaration}
	\addcontentsline{toc}{chapter}{Plagiarism Declaration}
	\begin{enumerate}
		\item
			I know that plagiarism means taking and using the ideas, writings, works or inventions of another as if they were one's own. I know that plagiarism not only includes verbatim copying, but also the extensive use of another person's ideas without proper acknowledgement (which includes the proper use of quotation marks). I know that plagiarism covers this sort of use of material found in textual sources and from the Internet.
		\item
			I acknowledge and understand that plagiarism is wrong.
		\item
			I understand that my research must be accurately referenced. I have followed the rules and conventions concerning referencing, citation and the use of quotations as set out in the Departmental Guide.
		\item
			This assignment is my own work, or my group's own unique group assignment.
			I acknowledge that copying someone else's assignment, or part of it, is wrong, and that submitting identical work to others constitutes a form of plagiarism.
		\item
			I have not allowed, nor will I in the future allow, anyone to copy my work with the intention of passing it off as their own work.
	\end{enumerate}
	Jason David Russell

\newpage
\chapter*{Acknowledgements}
	\addcontentsline{toc}{chapter}{Acknowledgements}
	I acknowledge everything.

\newpage
\chapter*{Abstract}
	\addcontentsline{toc}{chapter}{Abstract}
	This paper investigates the viability of a new indoor positioning system which is to make use of the comparison of digital imagery to 3D models. An example scenario would be a person wishing to know which room they are in within a building. A 3D model of the building exists. The person takes a few photographs of her surroundings, the photographs are then compared to the 3D model and the result is presented to the person. The main focus of this paper is on the matching of the images to the 3D model.

\newpage
\tableofcontents

\newpage
\listoffigures

\pagenumbering{arabic}
\setcounter{page}{0}

\newpage
\chapter{Introduction}
	\section{Subject of the Report}
		This report concerns the viability of an alternate indoor positioning method. The method involves comparing a photograph to a 3D interior model in order to determine the location of the photographer.
	
	\section{Background to the Report}
		3D interior models are becoming more and more prominent. New technological advancements and techniques are making it cheaper, quicker and easier to generate interior 3D models. Combine the recent prominence of 3D interior models with the ubiquity of camera equipped smart phones and a new indoor positioning system presents itself. This system depends on the matching of a photograph to a 3D interior model in order to locate the photographer. Thus, the primary focus of this paper is on the matching of a photograph to a 3D interior model.
	
	\section{Objectives of the Report}
		The objectives of this report are therefore to:
		\begin{itemize}
			\item
				discuss related work
			\item
				discuss the alternate method and its requirements
			\item
				present experimental results
			\item
				 consider future work
			\item
				draw conclusions
		\end{itemize}
	
	\section{Scope and limitations}
		Some scope and limitation stuff goes here.
	
	\section{Plan of Development}
		This report begins by looking at work related to indoor positioning systems. Following on from that, the alternate method will be proposed. Thereafter results of investigations will be presented and discussed.

\newpage
\chapter{Related Work}
	In the sections to follow, existing indoor positioning systems will be discussed. Two main branches of technologies will be covered, namely radio and non-radio technologies.
	
	\section{Radio technologies}
		Any wireless technology can in theory, be used for positioning. Three main techniques exist, each one will be briefly outlined below. The sections to follow will look at existing systems which employ these techniques.
	
	\subsection{Time of arrival}
		\begin{figure}[h!]
			\centering
			\includegraphics[width=0.6\textwidth]{time_of_arrival}
			\caption{Time of arrival}
		\end{figure}
		Time of arrival (or time of flight) is the travel time of a radio signal from a single transmitter to a single remote receiver. The basic observable is time. A Distance can be directly calculated using the known propagation velocity of signals with the basic observable time. Location can then be determined using multi-lateration. This requires a setup of at least one receiver and three transmitters or vise versa.
		Required with such systems is the synchronization of clocks between receivers and transmitters.
		Time of travel systems suffer greatly from effects such as multi-path.
		\cite{k._pahlavan_wideband_1998}
	
	\subsection{Received signal strength indication}
		\begin{figure}[h!]
			\centering
			\includegraphics[width=0.6\textwidth]{rssi}
			\caption{RSSI}
		\end{figure}
		Received signal strength indication is a measure of the power level received by a sensor. Because of how radio waves propagate, distance can be approximated between a transmitter and receiver based on the relationship between the transmitted and received signal strength. Multi-lateration can be used to determine locality of a sensor.
	
	\subsection{Angle of arrival}
		\begin{figure}[h!]
			\centering
			\includegraphics[width=0.6\textwidth]{angle_of_arrival}
			\caption{Angle of arrival}
		\end{figure}
		Angle of arrival is the angle from which a signal is received at a receiver. Angle of arrival is typically determined by using the time difference of arrival between multiple antennas in a sensor array. Position is determined using multi-angulation.
		Angle of arrival systems also suffer from effects such as multi-path.
	
	\subsection{Wi-Fi based systems}
		Wi-Fi based technologies are based on measurements such as TOA (time of arrival), TDOA (time difference of arrival) and DOA (direction of arrival). However these techniques are severely impaired when line of sight is not achievable. These techniques also suffer due to objects such as walls and floors and other objects which attenuate and reflect the signals, directly affecting accuracies.
	
		An alternative Wi-Fi based geolocation method has been explored which makes use of relative signal strengths between transmitters and receivers. So instead of measuring the time or angle of signals, the signal strength is used to determine location. This negates many of the above mentioned deficiencies. A similar system has been employed by animal trackers with directional antennas.
		\cite{yongguang_chen_signal_2002}
	
	\subsection{Blue-tooth systems}
		Blue-tooth positioning works by using proximities, as opposed to angulation or lateration. As such, exact locations are not attainable using these techniques. Instead, the system acts more as a geofence and works by determining which node a device is currently connected to in order to determine the location of the device.
	
		Apple has developed a protocol called iBeacon. This protocol makes use fo Blue-tooth proximity techniques in order to enable smart devices to perform actions when in close proximity to iBeacon.
		\cite{_everything_????}
	
	\subsection{Choke point concepts}
		Choke point systems work by locating and indexing tagged objects in order to track them. The concept works by passing tagged objects though a choke point (or gate), the choke point will then have a sensor which detects the tagged object passing through the gate. Many choke point sensors work with passive radio-frequency identification (RFID) tags which do not report distances or signal strengths.
		\cite{reza_investigation_2008}
	
	\subsection{Grid concepts}
		Grid concepts employ a dense network of low-range receivers arranged in a known pattern. A tagged object will be sensed by only a few nearby, networks receivers. By determining which receivers and tag is sensed by, a rough approximation of the location of the tagged object can be made.
	
	\subsection{Others}
		Various other systems exist but will not be discussed further. These include ultra-wide band (UWB), infra-red (IR), visible light communication, and ultrasound.
	
	\section{Non-radio technologies}
		Non-radio technologies which can be used for indoor positioning will be discussed below. These systems can provide increased accuracy at the expense of increased costs of equipment and additional installations.
	
	\subsection{Magnetic positioning}
		Magnetic positioning takes advantage of the way iron in buildings affects the Earth's magnetic field. The iron in buildings creates local variations in the Earth's magnetic field which can then be sensed by compasses to map indoor locations.
		\cite{supreeth_sudhakaran_geospatial_2014}
	
	\subsection{Inertial measurements}
		Inertial measurement units (IMUs) can be carried by an object in order to track the objects path through space. IMUs measure acceleration and orientation along three orthogonal axis using accelerometers and gyroscopes. Position can be determined by double integration of the acceleration measurements - this is a form of dead reckoning. Dead reckoning is the process of calculating ones current location by using previously determined positions with estimated speed and orientation over some time. This yields relative position estimations. Dead reckoning is subject to what is known as drift which is an accumulation of errors. Due to the susceptibility of IMUs to drift, they are often used in conjunction with other positioning systems in order to correct for this drift.

\newpage
\chapter{Method}
	There are two main requirements for this alternate indoor positioning method. The first requirement is to have a 3D model of an environment. The second requirement is a photograph of a scene within that environment. The premise is that the photograph could be matched against the 3D model in order to determine where the photograph was taken within that 3D model, thus locating the photographer. The focus of this paper is on the comparison of the photograph and the model, as if this is not feasible, the premise is flawed.
	
	The querying of the photograph against the model presents a problem, and that is that the photograph and the 3D model are not intrinsically comparable. So how does one compare an image to a 3D model? A solution to this problem is to create renderings throughout the model and compare these renderings to the photograph. These renderings are themselves images and so this permits the use of advanced and robust image recognition software to perform the matching.
	
	In the following sections, the processes of creating the 3D interior model, taking a photograph and comparing the photograph to the renders of the 3D model will be discussed in detail.
	
	The model is to be as close to the photograph as possible to try and get as high quality of a match as possible. {{elaborate}}
	
	The front door section of the Geomatics Teaching Laboratory was used as the basis of this investigation. The Geomatics Teaching Laboratory is located on the fifth floor of the Menzies building at UCT. The section under investigation is the south east corner of the room and was selected as there are a number of favourable features which are expected to maximize the chances of a high quality match. Some of these favourable features include the whiteboard, doors, skirting, air-conditioner vents as well as the double lipped corner with a conduate running along an edge. More on this later.
	
	\section{Photograph}
		The test photograph for this investigation is of the front door section of the GTL room. The scene consists of a air-conditioning duct on which there is a vent. On the left of the image is a section of a pin board, which contains a number of newspaper clippings. In the centre of the image is the corner of the room. The corner is relatively complex with a number of conduates running to the floor, with an electrical plug box. The blue door is symmetrical with the exception of the bottom panels where the right hand door as a black ventilation panel. The other three panels are semi transparent glass panes which allow diffused light to enter the room.
		
		The photograph was taken using an iPhone 4S camera, which is actually an eight megapixel Sony Exmor R IMX 145.
		
		\begin{figure}[h!]
			\centering
			\includegraphics[width=0.6\textwidth]{gtl_door_area}
			\caption{GTL Door area}
		\end{figure}

	
	\newpage
	\section{The 3D model}
		3D modelling can be described as the process of developing a mathematical representation of a three dimensional space using specialized software. The product of this process is called a 3D model. A 3D model can be visualized as a two dimensional image through a process called 3D rendering. It is this two dimensional image representation of a 3D model which is utilized in order to perform the comparison to a photograph in this alternate indoor positioning system.
		
		\subsection{Model creation}
			3D models can be created automatically or manually. Examples of automatic techniques include structure from motion. Manual creation of 3D models involves construction by hand using advanced computer software such as Blender. In order to accurately model an existing environment, raw data such as measurements or point clouds is needed to serve as a basis for the model creation, it serves as the initial building block for the model. This raw data can be in a variety of forms, this will be discussed in the section to follow.
		
			\subsubsection{Data acquisition}
				In order to create an accurate 3D model of a building, data is required in order to aid the modelling process and serve as a template or reference. This data can come in the form of building plans, measured distances and directions or point clouds etc.
				
				For this investigation, a point cloud was used. A laser scan of the Geomatics Teaching Laboratory (GTL) was carried out using a {{laser Scanner model}} at {{laser scanner settings, resolution etc}}. The end result was a high resolution point cloud of the rooms interior. 
				
				{{Insert Point Cloud image}}.
				
			\subsubsection{Data preprocessing}
				During a scan, it often happens that a scanner captures points which are irrelevant. These points may include points which are considered unneeded in a particular scan. Typical examples of such cases leading to irrelevant points are people walking through a scan, reflections of the scan laser beam off of surfaces or points from objects which are deemed irrelevant. Point clouds can be cleaned manually by hand, or using automated techniques. The point cloud in question was manually cleaned in a software program called CloudCompare.
				
				\begin{figure}[h!]
					\centering
					\includegraphics[width=0.9\textwidth]{cleaned_pc}
					\caption{Cleaned point cloud of focus area}
				\end{figure}
				
				The density of the point cloud was also made to be consistent. Due to laser beam divergence, points nearer to the scanner are packed more densely. An operation was performed on the point cloud which ensured uniform point density throughout the cloud. This processes reduces the point cloud's size which in turn makes handling the point cloud less computationally intensive.
				\cite{_selection_????}
				
			\subsubsection{Constructing the model}
				Solid modelling is a consistent set of principles for mathematical and computer modelling of three-dimensional solids which forms the foundation of computer-aided model design. 
				\cite{vadim_shapiro_solid_2001}
				
				Boundary representation (B-rep) is a solid representation scheme. It is a method for representing shapes using limits. In boundary representation a solid is represented as a collection of connected surfaces. The surfaces themselves are created using topological items: faces, edges and vertices.
				\cite{hongxin_zhang_introduction_2007}
				
				The model in this investigation was created using boundary representation. A per-processed and cleaned point cloud of GTL was used to serve as a template. The software used to create and manipulate the 3D model was Blender. Blender is a free and open-source computer graphics software product. The cleaned point cloud was loaded into Blender. Faces were attached to points in order to create the outline of the room, the outline consisted of the four surrounding walls, floor and ceiling.
				
				\begin{figure}[h!]
					\centering
					\includegraphics[width=0.9\textwidth]{simple_model_with_pc}
					\caption{Front view of simple model}
				\end{figure}
				
				Detail of the model was iteratively increased by modelling finer and finer details.
				
				\begin{figure}[h!]
					\centering
					\includegraphics[width=0.9\textwidth]{model_with_increased_detail}
					\caption{Model with increased detail}
				\end{figure}
				
				The image above shows the model with increased detail. The skirting board, conduate, door as well as white-boards have now been added. All these features have been modelled from the point cloud and so the model is an accurate representation of the actual room in terms of scale etc.
				
		\subsection{Level of detail}
			In terms of 3D modelling, level of detail refers to how thoroughly real-world features have been modelled and how much those model features resemble their real-world counterparts.
			
			\begin{figure}[h!]
				\centering
				\includegraphics[width=0.6\textwidth]{level_of_detail_example}
				\caption{Level of detail example}
			\end{figure}
			
			The figure above illustrates the concept of level of detail. A sphere has been modelled at various levels of detail, decreasing from left to right.
			
			\subsubsection{Features}
				As many features as possible have been modelled within the area of investigation. This has been done in order to maximise the chance of a high quality match to the photograph as well as to facilitate testing and experimenting with the effect of various levels of detail on the accuracy of a matches. 
				
				This includes the modelling of the wall skirting, the electrical wire conduate, as well as fine details around the whiteboard. 
				
			\subsubsection{Lighting}
				Lighting is a very important component of any 3D model. Lighting can drastically alter the appearance of a model as well as its accuracy. When creating the model for this investigation, a great deal of attention was paid to lighting. Each consideration is discussed in detail below.
				
				\paragraph{Light source}
					The GTL room is illuminated by florescent light panels, each containing three fluorescent tubes. The panels are rectangular with dimensions 0.5m by 1.5m. Additionally, light enters the room from the windows along the north wall, as well as through the glass panels within the door. So there are three sources of light illuminating the room. When modelling light sources, there are a few considerations which need to be made, they are detailed in the paragraphs which follow.
					\subparagraph{Colour temperature}
						The colour temperature of a light source is the temperature of an ideal black-body radiator that radiates light of comparable hue to that of the light source. Colour temperatures are typically statued in the unit of absolute temperature, the Kelvin, with the symbol K.
						\begin{figure}[h!]
							\centering
							\includegraphics[width=0.6\textwidth]{colour_temperature}
							\caption{Colour temperatures}
						\end{figure}
						The figure above shows how colour temperatures relate to real world scenarios.
				
					\subparagraph{Position of lights}
						In order to accurately replicate shadows and intensities, the lighting in the model needs to be strategically placed and calibrated. The overhead lights have been placed in their respective real-world potions. Three emmisive planes have been placed behind the glass panels of the door area in order to replicate the real-world lighting.
						
						\begin{figure}[h!]
							\centering
							\includegraphics[width=0.6\textwidth]{overhead_lights}
							\caption{Overhead florescent lights}
						\end{figure}
						\begin{figure}[h!]
							\centering
							\includegraphics[width=0.6\textwidth]{lights_behind_door}
							\caption{Emmisive planes behind door replicate sunlight}
						\end{figure}
					
					\subparagraph{Light intensity}
						Luminous intensity is a measure of the wavelength-weighted power emitted by a light source in a particular direction. In order to accurately model the real world lighting intensities in the model, each light source was adjusted individually and judged by simple visual inspection. 
						
						One important consideration here is that because the Earth rotates about its axis as well as around the sun, perceived sun light varies. For the sake of this investigation, the lighting conditions were assumed to be that of midday, which was when the photographs for comparison were taken. {{Need more here, clouds affect light etc}}
						
				\subsubsection{Texture}
					Surface finish, also known as surface texture or surface topography, is the nature of a surface as defined by three characteristics of lay, surface roughness and waviness.
					\cite{e._paul_degarmo_materials_2003}
					Particular attention has been paid to accurately representing surface characteristics of as many features as possible in the model.
					The panels in the door are set to be smooth and transparent, replicating the real-world glass panes. 
					The texture of the walls has been adjusted.
					The texture of the floor has been roughened to replicate the carpet.
					The whiteboards are smooth and glossy.
					The gray pin board has a rough texture.
			
			\subsection{Renderings}
				Rendering can be described as the process of generating an image from a 2D or 3D model by means of computer programs. Renders can either be generated in real-time, or pre-rendered. Examples of real-time renderings include 3D video games.
				
				Blender offers three types of renderer engines, Blender, Cycles, and Game renderers. For this investigation, the Cycles renderer was used as it offered superior results.
				
				{{Insert rendered images here}} 
				
				Discus 
			
			\subsubsection{Draft}
				3D model
					Model creation
						data acquisition
							data from laser scan -> Point cloud
						data preprocessing
							cleaned point cloud -> removed unneeded points
							uniform density
						constructing model from raw data
							Intro to solid modelling
							Automated techniques failed
							Boundary rep
							Created model manually with blender + PC
					Model level of detail
						intro to LOD
						elements (degree of detail)
							include conduate, wall plugs, white-board seams etc
						lighting/shadows
							position of lights and shadows, type of lights
						texture
							rough texture for carpet, smooth texture for glass panel on door
						image draping
							image draped over air vent
					creating renderings of model
						types of renderers + their differences
						Cycles renderer used
						Discuss render parameters
			
		\section{Comparison of the model and photograph}
			This section of the methodology deals with the matching of the photograph to the render of the 3D model.
			\subsection{Draft}
				How feature detection works
				How feature matching works
				Homogrophy
				SIFT/SURF/ORB
					

\chapter{Experimental implementation results}

\chapter{Discussions}

\chapter{Conclusions and future work}

\newpage
\printbibliography

\end{document}